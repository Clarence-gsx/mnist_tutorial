{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a popular deep learning framework and it's easy to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the mnist data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the model, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "# TODO:define model\n",
    "    def __init__(self):\n",
    "        super(SimpleNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(320, 10)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0) # one batch\n",
    "        # x: 64*10*12*12\n",
    "        x = F.relu(self.mp(self.conv1(x)))\n",
    "        # x: 64*20*4*4\n",
    "        x = F.relu(self.mp(self.conv2(x)))\n",
    "        # x: 64*320\n",
    "        x = x.view(in_size, -1) # flatten the tensor\n",
    "        # x: 64*10\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "model = SimpleNet()\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/468 [00:00<?, ?it/s]/Users/clarence/CodeTheFuture/anaconda3/envs/ctw/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100%|██████████| 468/468 [00:26<00:00, 17.93it/s]\n",
      "100%|██████████| 468/468 [00:26<00:00, 17.60it/s]\n",
      "100%|██████████| 468/468 [00:26<00:00, 17.79it/s]\n",
      "100%|██████████| 468/468 [00:26<00:00, 17.89it/s]\n",
      "100%|██████████| 468/468 [00:26<00:00, 17.99it/s]\n",
      "100%|██████████| 468/468 [00:25<00:00, 18.31it/s]\n",
      "100%|██████████| 468/468 [00:25<00:00, 18.45it/s]\n",
      "100%|██████████| 468/468 [00:25<00:00, 18.02it/s]\n",
      "100%|██████████| 468/468 [00:25<00:00, 18.05it/s]\n",
      "100%|██████████| 468/468 [00:25<00:00, 18.03it/s]\n",
      "  1%|          | 3/468 [00:00<00:16, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:13<00:00, 35.12it/s]\n",
      "100%|██████████| 78/78 [00:02<00:00, 36.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # TODO:forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = F.nll_loss(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print('Train finished.')\n",
    "    # evaluate\n",
    "    # TODO:calculate the accuracy using traning and testing dataset\n",
    "train_acc=0\n",
    "test_acc=0\n",
    "for images, labels in tqdm(train_loader):\n",
    "    output = model(images)\n",
    "    pred = output.argmax(dim=1, keepdim=True)  \n",
    "    train_acc += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    \n",
    "for images, labels in tqdm(test_loader):\n",
    "    output = model(images)\n",
    "    pred = output.argmax(dim=1, keepdim=True)  \n",
    "    test_acc += pred.eq(labels.view_as(pred)).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5:\n",
    "Please print the training and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Accuracy: 58972/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Accuracy: 9822/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTrain set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_acc, len(train_loader.dataset),\n",
    "        100. * train_acc / len(train_loader.dataset)))\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_acc, len(test_loader.dataset),\n",
    "        100. * test_acc / len(test_loader.dataset)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
